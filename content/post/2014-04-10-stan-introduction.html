---
title: 베이즈 추정을 위한 Stan 맛보기
date: '2014-04-10'
categories: R
tags:
  - R
  - Stan
slug: stan-introduction
---



<div class="section level2">
<h2>시작하며</h2>
<p>Bayesian inference using Gibbs sampling:BUGS는 베이즈 추정을 계산기 통계학적으로 수행하는 방법. “계산기 통계학적으로”라는 것은 복잡하고 어려운 함수기술에서 생략할 수 있는 부분은 생략해서 MCMC/Gibbs sampling으로 대체한다는 의미로 생각해도 좋음. 베이즈 추정을 하기 위해 우도 함수 등을 미리 구해 빡시게 코딩하는 것보다는 BUGS(WinBUGS, OpenBUGS, JAGS)등을 이용해 모델의 기술하고 실행한 후 결과를 확인하는 것이 편리. 그렇다고 해도 계산 시간이 오래 걸린다는 문제점은 남아 있음. 여기서는 Stan이라는 최근 많이 사용되는(것 같은?) 소프트웨어를 R에서 사용하는 방법에 대해 메모.</p>
</div>
<div id="stan-" class="section level2">
<h2>Stan의 개요</h2>
<p>Stan의 홈페이지는 <a href="http://mc-stan.org/%5D">여기</a>.</p>
<p>Stan의 개요에 대해서는 <a href="http://www.dynacom.co.jp/tech/tech_column/tech013.html">이곳</a>과 <a href="http://tjo.hatenablog.com/entry/2014/03/25/194605">이곳</a>(일본어)에서 번역 발췌.</p>
<p>모델의 기술방법에 약간의 차이가 있지만, BUGS와 같이 우선 모델을 기술. Stan은 기술된 모델을 일단 C++ 언어로 변환하여 컴파일하는 흐름. C++로 컴파일함으로 인해 고속처리를 기대할 수 있고 일단 컴파일된 모듈을 다른 데이터에도 이용할 수 있게 됨. BUGS에서는 별도의 데이터를 이용하기 위해서는 모델의 확인 -&gt; 데이터 지정 -&gt; 초기화 -&gt; 컴파일의 과정을 전부 다시 해야함. stan을 이용하면 이 과정이 생략되기 때문에 전체 실행 과정의 고속화를 꾀할 수 있음.</p>
<p>또한, C++ 이라는 언어의 특성상 모델의 기술이 엄격하게 되어 데이터의 형태 (int, real) 및 변수가 가질 수 있는 범위를 선언할 수 있게 됨. BUGS에서는 왜 샘플링 에러가 발생했는지 등에 대해 어림짐작으로 대응해야 하기 때문에 경험이 중요했음. 이러한 것들이 구체적으로 지적되기 때문에 디버깅이 편리해짐.</p>
<p>Stan에서 사용하는 난수 샘플링방법은 <a href="http://en.wikipedia.org/wiki/Hybrid_Monte_Carlo">Hamiltonian Monte Carlo Method</a>를 채용하여 수렴의 속도 및 안정성도 BUGS에 비해 향상됨.</p>
</div>
<div id="rstan" class="section level2">
<h2>Rstan</h2>
<p>환경설정은 <a href="https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started">이곳</a>을 참조.</p>
<p>기본적인 흐름은</p>
<ul>
<li>Rtools을 인스톨하여 CRAN에 등록되지 않은 패키지를 설치할 수 있게함</li>
<li><strong>Rcpp</strong> 패키지 및 <strong>inline</strong> 패키지을 이용해 Rcpp를 이용한 R의 C++화를 가능하게 하여 stan을 실행.</li>
</ul>
<pre class="r"><code>&gt; install.packages(&#39;inline&#39;)
&gt; install.packages(&#39;Rcpp&#39;)</code></pre>
<pre class="r"><code>&gt; # using library inline to compile a C++ code on the fly
&gt; library(inline) 
&gt; library(Rcpp)
&gt; src &lt;- &#39; 
+   std::vector&lt;std::string&gt; s; 
+   s.push_back(&quot;hello&quot;);
+   s.push_back(&quot;world&quot;);
+   return Rcpp::wrap(s);
+ &#39;
&gt; hellofun &lt;- cxxfunction(body = src, includes = &#39;&#39;, plugin = &#39;Rcpp&#39;, verbose = FALSE)
&gt; cat(hellofun(), &#39;\n&#39;) </code></pre>
<pre><code>#&gt; hello world</code></pre>
</div>
<div id="rstan-" class="section level2">
<h2>RStan의 설치</h2>
<div id="xcode-5.0.1-r-3.0.2-mac-os-x-10.9-mavericks---" class="section level3">
<h3>Xcode 5.0.1 + R 3.0.2 + Mac OS X 10.9 (Mavericks) 사용자를 위한 설정</h3>
<ul>
<li>실행환경</li>
<li>Mac OS X 10.9 (Mavericks),</li>
<li>Xcode toolset 5.0.1 &amp; command-line tools for Mavericks (Xcode와는 별도로 다운로드해야 함)</li>
<li>R 3.0.3</li>
</ul>
<p>다음 파일을 만들고</p>
<pre><code>~/.R/Makevars</code></pre>
<p>다음 내용을 입력</p>
<pre><code>CXX=g++ -arch x86_64 -ftemplate-depth-256 -stdlib=libstdc++</code></pre>
<p>R 에서 다음 코드를 실행</p>
<pre class="r"><code>&gt; if (!file.exists(&quot;~/.R/Makevars&quot;)) {
+   cat(&#39;CXX=g++ -arch x86_64 -ftemplate-depth-256 -stdlib=libstdc++\n
+        CXXFLAGS=&quot;-mtune=native  -O3 -Wall -pedantic -Wconversion&quot;\n&#39;, 
+        file=&quot;~/.R/Makevars&quot;);
+ } else {
+    file.show(&quot;~/.R/Makevars&quot;);
+ }</code></pre>
</div>
<div id="rstan-" class="section level3">
<h3>rstan 인스톨</h3>
<pre class="r"><code>&gt; options(repos = c(getOption(&quot;repos&quot;), rstan = &quot;http://wiki.rstan-repo.googlecode.com/git/&quot;))
&gt; install.packages(&#39;rstan&#39;, type = &#39;source&#39;)</code></pre>
</div>
<div id="rstan----" class="section level3">
<h3>rstan을 효율적으로 사용하기 위한 옵션</h3>
<pre class="r"><code>&gt; library(rstan)
&gt; set_cppo(&quot;fast&quot;)  # for best running speed
&gt; set_cppo(&#39;debug&#39;) # make debug easier</code></pre>
</div>
</div>
<div id="example" class="section level2">
<h2>Example</h2>
<p><a href="https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started#how-to-install-rstan">RStan Getting Started</a>의 예제 1번을 따라해보고 제대로 실행 되는가 확인.</p>
<pre class="r"><code>&gt; schools_code &lt;- &#39;
+   data {
+     int&lt;lower=0&gt; J; // number of schools 
+     real y[J]; // estimated treatment effects
+     real&lt;lower=0&gt; sigma[J]; // s.e. of effect estimates 
+   }
+   parameters {
+     real mu; 
+     real&lt;lower=0&gt; tau;
+     real eta[J];
+   }
+   transformed parameters {
+     real theta[J];
+     for (j in 1:J)
+       theta[j] &lt;- mu + tau * eta[j];
+   }
+   model {
+     eta ~ normal(0, 1);
+     y ~ normal(theta, sigma);
+   }
+ &#39;
&gt; 
&gt; schools_dat &lt;- list(J = 8, 
+                     y = c(28,  8, -3,  7, -1,  1, 18, 12),
+                     sigma = c(15, 10, 16, 11,  9, 11, 10, 18))
&gt; 
&gt; fit &lt;- stan(model_code = schools_code, data = schools_dat, 
+             iter = 1000, chains = 4)</code></pre>
<pre><code>#&gt; In file included from file1474bfae5ac5.cpp:8:
#&gt; In file included from /usr/local/lib/R/3.4/site-library/StanHeaders/include/src/stan/model/model_header.hpp:4:
#&gt; In file included from /usr/local/lib/R/3.4/site-library/StanHeaders/include/stan/math.hpp:4:
#&gt; In file included from /usr/local/lib/R/3.4/site-library/StanHeaders/include/stan/math/rev/mat.hpp:4:
#&gt; In file included from /usr/local/lib/R/3.4/site-library/StanHeaders/include/stan/math/rev/core.hpp:12:
#&gt; In file included from /usr/local/lib/R/3.4/site-library/StanHeaders/include/stan/math/rev/core/gevv_vvv_vari.hpp:5:
#&gt; In file included from /usr/local/lib/R/3.4/site-library/StanHeaders/include/stan/math/rev/core/var.hpp:7:
#&gt; In file included from /usr/local/lib/R/3.4/site-library/BH/include/boost/math/tools/config.hpp:13:
#&gt; In file included from /usr/local/lib/R/3.4/site-library/BH/include/boost/config.hpp:39:
#&gt; /usr/local/lib/R/3.4/site-library/BH/include/boost/config/compiler/clang.hpp:200:11: warning: &#39;BOOST_NO_CXX11_RVALUE_REFERENCES&#39; macro redefined [-Wmacro-redefined]
#&gt; #  define BOOST_NO_CXX11_RVALUE_REFERENCES
#&gt;           ^
#&gt; &lt;command line&gt;:6:9: note: previous definition is here
#&gt; #define BOOST_NO_CXX11_RVALUE_REFERENCES 1
#&gt;         ^
#&gt; 1 warning generated.
#&gt; 
#&gt; SAMPLING FOR MODEL &#39;31f989ec0d689be2a4996807325a264b&#39; NOW (CHAIN 1).
#&gt; 
#&gt; Gradient evaluation took 2.1e-05 seconds
#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds.
#&gt; Adjust your expectations accordingly!
#&gt; 
#&gt; 
#&gt; Iteration:   1 / 1000 [  0%]  (Warmup)
#&gt; Iteration: 100 / 1000 [ 10%]  (Warmup)
#&gt; Iteration: 200 / 1000 [ 20%]  (Warmup)
#&gt; Iteration: 300 / 1000 [ 30%]  (Warmup)
#&gt; Iteration: 400 / 1000 [ 40%]  (Warmup)
#&gt; Iteration: 500 / 1000 [ 50%]  (Warmup)
#&gt; Iteration: 501 / 1000 [ 50%]  (Sampling)
#&gt; Iteration: 600 / 1000 [ 60%]  (Sampling)
#&gt; Iteration: 700 / 1000 [ 70%]  (Sampling)
#&gt; Iteration: 800 / 1000 [ 80%]  (Sampling)
#&gt; Iteration: 900 / 1000 [ 90%]  (Sampling)
#&gt; Iteration: 1000 / 1000 [100%]  (Sampling)
#&gt; 
#&gt;  Elapsed Time: 0.042864 seconds (Warm-up)
#&gt;                0.042671 seconds (Sampling)
#&gt;                0.085535 seconds (Total)
#&gt; 
#&gt; 
#&gt; SAMPLING FOR MODEL &#39;31f989ec0d689be2a4996807325a264b&#39; NOW (CHAIN 2).
#&gt; 
#&gt; Gradient evaluation took 7e-06 seconds
#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.
#&gt; Adjust your expectations accordingly!
#&gt; 
#&gt; 
#&gt; Iteration:   1 / 1000 [  0%]  (Warmup)
#&gt; Iteration: 100 / 1000 [ 10%]  (Warmup)
#&gt; Iteration: 200 / 1000 [ 20%]  (Warmup)
#&gt; Iteration: 300 / 1000 [ 30%]  (Warmup)
#&gt; Iteration: 400 / 1000 [ 40%]  (Warmup)
#&gt; Iteration: 500 / 1000 [ 50%]  (Warmup)
#&gt; Iteration: 501 / 1000 [ 50%]  (Sampling)
#&gt; Iteration: 600 / 1000 [ 60%]  (Sampling)
#&gt; Iteration: 700 / 1000 [ 70%]  (Sampling)
#&gt; Iteration: 800 / 1000 [ 80%]  (Sampling)
#&gt; Iteration: 900 / 1000 [ 90%]  (Sampling)
#&gt; Iteration: 1000 / 1000 [100%]  (Sampling)
#&gt; 
#&gt;  Elapsed Time: 0.043324 seconds (Warm-up)
#&gt;                0.033921 seconds (Sampling)
#&gt;                0.077245 seconds (Total)
#&gt; 
#&gt; 
#&gt; SAMPLING FOR MODEL &#39;31f989ec0d689be2a4996807325a264b&#39; NOW (CHAIN 3).
#&gt; 
#&gt; Gradient evaluation took 7e-06 seconds
#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.
#&gt; Adjust your expectations accordingly!
#&gt; 
#&gt; 
#&gt; Iteration:   1 / 1000 [  0%]  (Warmup)
#&gt; Iteration: 100 / 1000 [ 10%]  (Warmup)
#&gt; Iteration: 200 / 1000 [ 20%]  (Warmup)
#&gt; Iteration: 300 / 1000 [ 30%]  (Warmup)
#&gt; Iteration: 400 / 1000 [ 40%]  (Warmup)
#&gt; Iteration: 500 / 1000 [ 50%]  (Warmup)
#&gt; Iteration: 501 / 1000 [ 50%]  (Sampling)
#&gt; Iteration: 600 / 1000 [ 60%]  (Sampling)
#&gt; Iteration: 700 / 1000 [ 70%]  (Sampling)
#&gt; Iteration: 800 / 1000 [ 80%]  (Sampling)
#&gt; Iteration: 900 / 1000 [ 90%]  (Sampling)
#&gt; Iteration: 1000 / 1000 [100%]  (Sampling)
#&gt; 
#&gt;  Elapsed Time: 0.042925 seconds (Warm-up)
#&gt;                0.048873 seconds (Sampling)
#&gt;                0.091798 seconds (Total)
#&gt; 
#&gt; 
#&gt; SAMPLING FOR MODEL &#39;31f989ec0d689be2a4996807325a264b&#39; NOW (CHAIN 4).
#&gt; 
#&gt; Gradient evaluation took 1.2e-05 seconds
#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds.
#&gt; Adjust your expectations accordingly!
#&gt; 
#&gt; 
#&gt; Iteration:   1 / 1000 [  0%]  (Warmup)
#&gt; Iteration: 100 / 1000 [ 10%]  (Warmup)
#&gt; Iteration: 200 / 1000 [ 20%]  (Warmup)
#&gt; Iteration: 300 / 1000 [ 30%]  (Warmup)
#&gt; Iteration: 400 / 1000 [ 40%]  (Warmup)
#&gt; Iteration: 500 / 1000 [ 50%]  (Warmup)
#&gt; Iteration: 501 / 1000 [ 50%]  (Sampling)
#&gt; Iteration: 600 / 1000 [ 60%]  (Sampling)
#&gt; Iteration: 700 / 1000 [ 70%]  (Sampling)
#&gt; Iteration: 800 / 1000 [ 80%]  (Sampling)
#&gt; Iteration: 900 / 1000 [ 90%]  (Sampling)
#&gt; Iteration: 1000 / 1000 [100%]  (Sampling)
#&gt; 
#&gt;  Elapsed Time: 0.046999 seconds (Warm-up)
#&gt;                0.041358 seconds (Sampling)
#&gt;                0.088357 seconds (Total)</code></pre>
<pre class="r"><code>&gt; fit2 &lt;- stan(fit = fit, data = schools_dat, iter = 10000, chains = 4)</code></pre>
<pre><code>#&gt; 
#&gt; SAMPLING FOR MODEL &#39;31f989ec0d689be2a4996807325a264b&#39; NOW (CHAIN 1).
#&gt; 
#&gt; Gradient evaluation took 1.1e-05 seconds
#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.11 seconds.
#&gt; Adjust your expectations accordingly!
#&gt; 
#&gt; 
#&gt; Iteration:    1 / 10000 [  0%]  (Warmup)
#&gt; Iteration: 1000 / 10000 [ 10%]  (Warmup)
#&gt; Iteration: 2000 / 10000 [ 20%]  (Warmup)
#&gt; Iteration: 3000 / 10000 [ 30%]  (Warmup)
#&gt; Iteration: 4000 / 10000 [ 40%]  (Warmup)
#&gt; Iteration: 5000 / 10000 [ 50%]  (Warmup)
#&gt; Iteration: 5001 / 10000 [ 50%]  (Sampling)
#&gt; Iteration: 6000 / 10000 [ 60%]  (Sampling)
#&gt; Iteration: 7000 / 10000 [ 70%]  (Sampling)
#&gt; Iteration: 8000 / 10000 [ 80%]  (Sampling)
#&gt; Iteration: 9000 / 10000 [ 90%]  (Sampling)
#&gt; Iteration: 10000 / 10000 [100%]  (Sampling)
#&gt; 
#&gt;  Elapsed Time: 0.382014 seconds (Warm-up)
#&gt;                0.589407 seconds (Sampling)
#&gt;                0.971421 seconds (Total)
#&gt; 
#&gt; 
#&gt; SAMPLING FOR MODEL &#39;31f989ec0d689be2a4996807325a264b&#39; NOW (CHAIN 2).
#&gt; 
#&gt; Gradient evaluation took 1.3e-05 seconds
#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.13 seconds.
#&gt; Adjust your expectations accordingly!
#&gt; 
#&gt; 
#&gt; Iteration:    1 / 10000 [  0%]  (Warmup)
#&gt; Iteration: 1000 / 10000 [ 10%]  (Warmup)
#&gt; Iteration: 2000 / 10000 [ 20%]  (Warmup)
#&gt; Iteration: 3000 / 10000 [ 30%]  (Warmup)
#&gt; Iteration: 4000 / 10000 [ 40%]  (Warmup)
#&gt; Iteration: 5000 / 10000 [ 50%]  (Warmup)
#&gt; Iteration: 5001 / 10000 [ 50%]  (Sampling)
#&gt; Iteration: 6000 / 10000 [ 60%]  (Sampling)
#&gt; Iteration: 7000 / 10000 [ 70%]  (Sampling)
#&gt; Iteration: 8000 / 10000 [ 80%]  (Sampling)
#&gt; Iteration: 9000 / 10000 [ 90%]  (Sampling)
#&gt; Iteration: 10000 / 10000 [100%]  (Sampling)
#&gt; 
#&gt;  Elapsed Time: 0.414159 seconds (Warm-up)
#&gt;                0.471325 seconds (Sampling)
#&gt;                0.885484 seconds (Total)
#&gt; 
#&gt; 
#&gt; SAMPLING FOR MODEL &#39;31f989ec0d689be2a4996807325a264b&#39; NOW (CHAIN 3).
#&gt; 
#&gt; Gradient evaluation took 9e-06 seconds
#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.
#&gt; Adjust your expectations accordingly!
#&gt; 
#&gt; 
#&gt; Iteration:    1 / 10000 [  0%]  (Warmup)
#&gt; Iteration: 1000 / 10000 [ 10%]  (Warmup)
#&gt; Iteration: 2000 / 10000 [ 20%]  (Warmup)
#&gt; Iteration: 3000 / 10000 [ 30%]  (Warmup)
#&gt; Iteration: 4000 / 10000 [ 40%]  (Warmup)
#&gt; Iteration: 5000 / 10000 [ 50%]  (Warmup)
#&gt; Iteration: 5001 / 10000 [ 50%]  (Sampling)
#&gt; Iteration: 6000 / 10000 [ 60%]  (Sampling)
#&gt; Iteration: 7000 / 10000 [ 70%]  (Sampling)
#&gt; Iteration: 8000 / 10000 [ 80%]  (Sampling)
#&gt; Iteration: 9000 / 10000 [ 90%]  (Sampling)
#&gt; Iteration: 10000 / 10000 [100%]  (Sampling)
#&gt; 
#&gt;  Elapsed Time: 0.340307 seconds (Warm-up)
#&gt;                0.461361 seconds (Sampling)
#&gt;                0.801668 seconds (Total)
#&gt; 
#&gt; 
#&gt; SAMPLING FOR MODEL &#39;31f989ec0d689be2a4996807325a264b&#39; NOW (CHAIN 4).
#&gt; 
#&gt; Gradient evaluation took 1.7e-05 seconds
#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.
#&gt; Adjust your expectations accordingly!
#&gt; 
#&gt; 
#&gt; Iteration:    1 / 10000 [  0%]  (Warmup)
#&gt; Iteration: 1000 / 10000 [ 10%]  (Warmup)
#&gt; Iteration: 2000 / 10000 [ 20%]  (Warmup)
#&gt; Iteration: 3000 / 10000 [ 30%]  (Warmup)
#&gt; Iteration: 4000 / 10000 [ 40%]  (Warmup)
#&gt; Iteration: 5000 / 10000 [ 50%]  (Warmup)
#&gt; Iteration: 5001 / 10000 [ 50%]  (Sampling)
#&gt; Iteration: 6000 / 10000 [ 60%]  (Sampling)
#&gt; Iteration: 7000 / 10000 [ 70%]  (Sampling)
#&gt; Iteration: 8000 / 10000 [ 80%]  (Sampling)
#&gt; Iteration: 9000 / 10000 [ 90%]  (Sampling)
#&gt; Iteration: 10000 / 10000 [100%]  (Sampling)
#&gt; 
#&gt;  Elapsed Time: 0.324616 seconds (Warm-up)
#&gt;                0.43039 seconds (Sampling)
#&gt;                0.755006 seconds (Total)</code></pre>
<pre class="r"><code>&gt; print(fit2)</code></pre>
<pre><code>#&gt; Inference for Stan model: 31f989ec0d689be2a4996807325a264b.
#&gt; 4 chains, each with iter=10000; warmup=5000; thin=1; 
#&gt; post-warmup draws per chain=5000, total post-warmup draws=20000.
#&gt; 
#&gt;           mean se_mean   sd   2.5%   25%   50%   75% 97.5% n_eff Rhat
#&gt; mu        7.93    0.07 5.28  -2.52  4.66  7.95 11.15 18.58  6149    1
#&gt; tau       6.58    0.09 5.67   0.23  2.46  5.22  9.06 20.69  3904    1
#&gt; eta[1]    0.38    0.01 0.93  -1.49 -0.23  0.40  1.02  2.15 20000    1
#&gt; eta[2]    0.00    0.01 0.88  -1.72 -0.58  0.00  0.57  1.75 20000    1
#&gt; eta[3]   -0.19    0.01 0.93  -1.99 -0.82 -0.20  0.42  1.67 20000    1
#&gt; eta[4]   -0.04    0.01 0.87  -1.77 -0.62 -0.04  0.54  1.71 20000    1
#&gt; eta[5]   -0.35    0.01 0.87  -2.05 -0.94 -0.36  0.22  1.40 14540    1
#&gt; eta[6]   -0.22    0.01 0.89  -1.95 -0.81 -0.23  0.36  1.57 20000    1
#&gt; eta[7]    0.34    0.01 0.89  -1.49 -0.24  0.36  0.94  2.06 20000    1
#&gt; eta[8]    0.05    0.01 0.93  -1.79 -0.56  0.06  0.68  1.87 20000    1
#&gt; theta[1] 11.29    0.07 8.24  -2.38  5.98 10.24 15.29 31.32 12612    1
#&gt; theta[2]  7.92    0.04 6.33  -4.60  3.92  7.90 11.77 21.01 20000    1
#&gt; theta[3]  6.15    0.06 7.64 -11.23  2.06  6.75 10.80 20.05 16560    1
#&gt; theta[4]  7.60    0.05 6.54  -5.86  3.65  7.66 11.62 20.62 20000    1
#&gt; theta[5]  5.21    0.04 6.30  -8.85  1.52  5.70  9.45 16.29 20000    1
#&gt; theta[6]  6.17    0.05 6.70  -8.74  2.33  6.57 10.44 18.51 20000    1
#&gt; theta[7] 10.66    0.05 6.77  -1.13  6.15 10.00 14.49 25.88 20000    1
#&gt; theta[8]  8.48    0.06 7.86  -6.90  3.87  8.21 12.74 25.60 17026    1
#&gt; lp__     -4.85    0.03 2.61 -10.61 -6.42 -4.63 -3.00 -0.44  5741    1
#&gt; 
#&gt; Samples were drawn using NUTS(diag_e) at Sun Jan  7 22:48:24 2018.
#&gt; For each parameter, n_eff is a crude measure of effective sample size,
#&gt; and Rhat is the potential scale reduction factor on split chains (at 
#&gt; convergence, Rhat=1).</code></pre>
<pre class="r"><code>&gt; plot(fit2)</code></pre>
<pre><code>#&gt; &#39;pars&#39; not specified. Showing first 10 parameters by default.</code></pre>
<pre><code>#&gt; ci_level: 0.8 (80% intervals)</code></pre>
<pre><code>#&gt; outer_level: 0.95 (95% intervals)</code></pre>
<p><img src="/post/2014-04-10-stan-introduction_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code>&gt; la &lt;- extract(fit2, permuted = TRUE) # return a list of arrays 
&gt; mu &lt;- la$mu 
&gt; 
&gt; ### return an array of three dimensions: iterations, chains, parameters 
&gt; a &lt;- extract(fit2, permuted = FALSE) 
&gt; 
&gt; ### use S3 functions as.array (or as.matrix) on stanfit objects
&gt; a2 &lt;- as.array(fit2)
&gt; m &lt;- as.matrix(fit2)</code></pre>
</div>
